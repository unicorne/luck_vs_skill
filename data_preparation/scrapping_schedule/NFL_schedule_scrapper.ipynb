{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scrapping_utils import url_get_contents, get_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping the schedule of the NFL season"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from e.g here: http://www.espn.com/nfl/schedulegrid/_/year/2018 for the 2018 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schedule_from_espn(url):\n",
    "    \"\"\"Reformat schedule table from espn site to fit our needs\"\"\"\n",
    "    # Scrape table from espn.com\n",
    "    ptables = get_tables(url)\n",
    "\n",
    "    # Preprocessing to remove unnecessary information after scrapping\n",
    "    df = pd.DataFrame(ptables[0])\n",
    "    df.columns = df.iloc[1]\n",
    "    df = df.drop(df.index[0])\n",
    "    df = df.drop(df.index[0])\n",
    "    df = df.replace(np.nan, \"BYE\")\n",
    "\n",
    "    # replace all away games to BYE to remove them later to avoid duplicates\n",
    "    for col in df.columns:\n",
    "        if col == \"TEAM\":\n",
    "            continue\n",
    "        else:\n",
    "            df.loc[df[col].str.contains(\"@\"), col] = \"BYE\"\n",
    "\n",
    "    # melt the table to be in Home/Away format\n",
    "    df = df.melt(\"TEAM\", var_name=\"Week\", value_name=\"Opponent\")\n",
    "    # remove BYE weeks and duplicates\n",
    "    df = df[df[\"Opponent\"] != \"BYE\"]\n",
    "    df = df.drop(\"Week\", axis=1)\n",
    "    df = df.rename(columns={\"TEAM\": \"Home\", \"Opponent\": \"Away\"})\n",
    "    df = df.drop_duplicates(subset=[\"Home\", \"Away\"])\n",
    "    df = df[[\"Home\", \"Away\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2002, 2022)\n",
    "urls = [f\"http://www.espn.com/nfl/schedulegrid/_/year/{year}\" for year in years]\n",
    "\n",
    "for year, url in zip(years, urls):\n",
    "    df_tmp = get_schedule_from_espn(url)\n",
    "    df_tmp.to_csv(f\"../../prepared_data/schedules/NFL/{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luckskill",
   "language": "python",
   "name": "luckskill"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "747efc146e86a5912f26e5d6b10798b21cba29e4347effd8c7cc42f26245deaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}